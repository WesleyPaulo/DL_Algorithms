{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4fe6e1",
   "metadata": {},
   "source": [
    "# Instalando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas tensorflow scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e687a2",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36556047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e4e40",
   "metadata": {},
   "source": [
    "# --- 1. Pré-processamento dos Dados ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb89ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset. O arquivo original não tem cabeçalho, então precisamos defini-lo.\n",
    "# Os dados devem ser lidos com a codificação 'ISO-8859-1'.\n",
    "df = pd.read_csv('sentiment140.csv', encoding='ISO-8859-1', header=None)\n",
    "\n",
    "# O dataset tem 6 colunas. A coluna 0 é o rótulo de sentimento e a 5 é o texto.\n",
    "# Rótulo 0: Negativo, Rótulo 4: Positivo.\n",
    "# Vamos mapear os rótulos para 0 (negativo) e 1 (positivo) para a classificação binária.\n",
    "df = df.iloc[:, [0, 5]]\n",
    "df.columns = ['target', 'text']\n",
    "df['target'] = df['target'].replace({0: 0, 4: 1})\n",
    "\n",
    "# Amostragem para reduzir o tempo de processamento.\n",
    "# Pegamos uma amostra aleatória de 50.000 tweets.\n",
    "df = df.sample(n=50000, random_state=24).reset_index(drop=True)\n",
    "\n",
    "# Função de limpeza do texto\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Converter para minúsculas\n",
    "    text = re.sub(\"https?://\\\\S+|www\\\\.\\\\S+\", '', text)  # Remover URLs\n",
    "    text = re.sub('@\\\\S+', '', text)  # Remover menções (@usuario)\n",
    "    text = re.sub('#', '', text)  # Remover o símbolo da hashtag\n",
    "    text = re.sub('[\\\\W\\\\d_]+', ' ', text)  # Remover caracteres especiais, números e underscores\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Tokenização e Sequenciamento\n",
    "# Criar um vocabulário com as palavras\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Converter o texto em sequências de números\n",
    "X = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "# Padding para garantir que todas as sequências tenham o mesmo tamanho\n",
    "max_len = 50\n",
    "X = pad_sequences(X, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Preparar os rótulos (Y)\n",
    "y = df['target'].values\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72fc3",
   "metadata": {},
   "source": [
    "# --- 2. Implementação da RNN (LSTM) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurações\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "\n",
    "# Construção do modelo sequencial\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))  # Dropout para regularização\n",
    "model.add(LSTM(lstm_units))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f8965",
   "metadata": {},
   "source": [
    "# --- 3. Treinamento do Modelo ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo e salvar o histórico para plotar as curvas de erro\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# --- 4. Avaliação e Resultados ---\n",
    "\n",
    "# Avaliar o desempenho no conjunto de teste\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'\\nPerda (Loss) no conjunto de teste: {loss:.4f}')\n",
    "print(f'Acurácia (Accuracy) no conjunto de teste: {accuracy:.4f}')\n",
    "\n",
    "# Plotar as curvas de acurácia e perda\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot da Acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Acurácia de Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.title('Curva de Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot da Perda (Loss)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Perda de Treino')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Curva de Perda')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"plot.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebebc9",
   "metadata": {},
   "source": [
    "# --- 4. Exemplos de Predições ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6567b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar 5 exemplos do conjunto de teste\n",
    "# Dividir o DataFrame de textos também\n",
    "text_train, text_test, _, _ = train_test_split(df['text'], y, test_size=0.2, random_state=24, stratify=y)\n",
    "\n",
    "sample_tweets = X_test[:5]\n",
    "true_labels = y_test[:5]\n",
    "sample_predictions = (model.predict(sample_tweets) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Acessar os textos originais do novo DataFrame de teste\n",
    "text_test_samples = text_test.iloc[:5].values\n",
    "\n",
    "print(\"\\n--- Exemplos de Predições ---\")\n",
    "for i in range(5):\n",
    "    prediction_label = \"Positivo\" if sample_predictions[i] == 1 else \"Negativo\"\n",
    "    true_label = \"Positivo\" if true_labels[i] == 1 else \"Negativo\"\n",
    "    \n",
    "    result = \"✅ Correto\" if sample_predictions[i] == true_labels[i] else \"❌ Incorreto\"\n",
    "    \n",
    "    print(f\"\\nTweet: {text_test_samples[i]}\")\n",
    "    print(f\"Predição: {prediction_label}\")\n",
    "    print(f\"Rótulo Verdadeiro: {true_label}\")\n",
    "    print(f\"Resultado: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
