{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62fb2b6",
   "metadata": {},
   "source": [
    "# Instalando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5670208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: matplotlib in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: pandas in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: seaborn in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pessoal\\ufpb\\dl\\atividades\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch matplotlib pandas seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0efa1a",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0742cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce7140",
   "metadata": {},
   "source": [
    "# --- 1. Limpeza e pré-processamento de dados ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54853e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Colunas não usadas\n",
    "    columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived']\n",
    "    df.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    # Converte pra float\n",
    "    numerical_features = ['Age', 'Fare', 'Parch', 'SibSp']\n",
    "    for col in numerical_features:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "    \n",
    "    # Trata valores faltantes\n",
    "    if 'Age' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    if 'Fare' in df.columns:\n",
    "        df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    if 'Embarked' in df.columns:\n",
    "        df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    \n",
    "    # Cria nova feature\n",
    "    if 'SibSp' in df.columns and 'Parch' in df.columns:\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "    \n",
    "    # One-hot encode \n",
    "    cols_to_get_dummies = [col for col in ['Sex', 'Embarked'] if col in df.columns]\n",
    "    df = pd.get_dummies(df, columns=cols_to_get_dummies, drop_first=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Carrega e pré-processa dados\n",
    "train_df_raw = pd.read_csv('train.csv')\n",
    "test_df_raw = pd.read_csv('test.csv')\n",
    "\n",
    "train_df = preprocess_data(train_df_raw.copy())\n",
    "test_df = preprocess_data(test_df_raw.copy())\n",
    "\n",
    "X_train_full = train_df\n",
    "y_train_full = train_df_raw['Survived']\n",
    "X_test = test_df\n",
    "\n",
    "# Confere se os 2 dataframes tem a mesmas features\n",
    "missing_cols_in_test = set(X_train_full.columns) - set(X_test.columns)\n",
    "for c in missing_cols_in_test:\n",
    "    X_test[c] = 0\n",
    "\n",
    "X_test = X_test[X_train_full.columns]\n",
    "\n",
    "# Data splitting\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X_train_full))\n",
    "split_idx = int(0.8 * len(indices))\n",
    "train_indices = indices[:split_idx]\n",
    "val_indices = indices[split_idx:]\n",
    "\n",
    "X_train = X_train_full.iloc[train_indices].copy()\n",
    "y_train = y_train_full.iloc[train_indices].copy()\n",
    "X_val = X_train_full.iloc[val_indices].copy()\n",
    "y_val = y_train_full.iloc[val_indices].copy()\n",
    "\n",
    "# StandardScaler\n",
    "numerical_features_to_scale = ['Age', 'Fare', 'FamilySize']\n",
    "\n",
    "# Tratamento de erros\n",
    "for col in numerical_features_to_scale:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = X_train[col].astype(float)\n",
    "        X_val[col] = X_val[col].astype(float)\n",
    "        X_test[col] = X_test[col].astype(float)\n",
    "\n",
    "train_mean = X_train.loc[:, numerical_features_to_scale].mean()\n",
    "train_std = X_train.loc[:, numerical_features_to_scale].std()\n",
    "\n",
    "X_train.loc[:, numerical_features_to_scale] = (X_train.loc[:, numerical_features_to_scale] - train_mean) / train_std\n",
    "X_val.loc[:, numerical_features_to_scale] = (X_val.loc[:, numerical_features_to_scale] - train_mean) / train_std\n",
    "X_test.loc[:, numerical_features_to_scale] = (X_test.loc[:, numerical_features_to_scale] - train_mean) / train_std\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6921f",
   "metadata": {},
   "source": [
    "# --- 2. PyTorch Dataset e DataLoader ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83198e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
    "        if labels is not None:\n",
    "            self.labels = torch.tensor(labels.values, dtype=torch.float32).unsqueeze(1)\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "        return self.features[idx]\n",
    "\n",
    "# Cria datasets e data loaders\n",
    "train_dataset = TitanicDataset(X_train, y_train)\n",
    "val_dataset = TitanicDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b56eb",
   "metadata": {},
   "source": [
    "# --- 3. Implementação da MLP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821f89a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Training Loss: 0.3835, Validation Loss: 0.3955\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) # \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = MLP(input_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinamento\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Validação\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "    \n",
    "    val_losses.append(val_running_loss / len(val_loader))\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e53f9a",
   "metadata": {},
   "source": [
    "# --- 4. Avaliação e Visualização ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60614670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia do modelo no conjunto de validação: 0.8268\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plotagem\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Erro de Treinamento')\n",
    "plt.plot(val_losses, label='Erro de Validação')\n",
    "plt.title('Curvas de Erro por Época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Erro (Perda)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_curve_pytorch.png')\n",
    "plt.close()\n",
    "\n",
    "# Avalia e valida\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "y_pred_val_tensor = torch.sigmoid(model(torch.tensor(X_val.values, dtype=torch.float32)))\n",
    "y_pred_val_binary = (y_pred_val_tensor.squeeze() > 0.5).int()\n",
    "\n",
    "# Cálculo manual de matriz de confusão e acurácia\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    true_positive = ((y_true == 1) & (y_pred == 1)).sum().item()\n",
    "    true_negative = ((y_true == 0) & (y_pred == 0)).sum().item()\n",
    "    false_positive = ((y_true == 0) & (y_pred == 1)).sum().item()\n",
    "    false_negative = ((y_true == 1) & (y_pred == 0)).sum().item()\n",
    "    \n",
    "    cm = np.array([[true_negative, false_positive], [false_negative, true_positive]])\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "    return cm, accuracy\n",
    "\n",
    "cm, accuracy = calculate_metrics(y_val_tensor, y_pred_val_binary)\n",
    "print(f\"\\nAcurácia do modelo no conjunto de validação: {accuracy:.4f}\")\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Não Sobreviveu', 'Sobreviveu'],\n",
    "            yticklabels=['Não Sobreviveu', 'Sobreviveu'])\n",
    "plt.title('Matriz de Confusão (Conjunto de Validação)')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.savefig('confusion_matrix_pytorch.png')\n",
    "plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
